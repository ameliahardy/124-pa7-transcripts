#########################################################################################
# TODO: Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): YES
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): YES
FEATURE - Alternate/foreign titles: YES
FEATURE - Disambiguation (part 1): YES
FEATURE - Fine-grained sentiment extraction: YES
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: YES
FEATURE - Disambiguation (part 2): YES
FEATURE - Dialogue for spell-checking: YES
FEATURE - Dialogue for disambiguation: YES
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: YES
FEATURE - Responding to arbitrary input: YES
FEATURE - Identifying and responding to emotions: NO
FEATURE - Chatbot theme/persona: YES
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################
Anavi Baddepudi: Extract_sentiment,Process,Word phrases Ethics/theme, titles, Dialogue, Extract sentiment from movies
Andrei Mandelshtam: Extract sentiment from movies, find movies closest to title, Chatbot theme, extract titles (as well
as creative), find movies by title creative, Binarize, handling extra edge cases in finding titles, extract sentiment
creative, chatbot intro
Emma Wang: Recommend, Process, Chatbot theme, dialogues, Extract Titles, Disambiguate, find movies by title, Dialogue
Ishan Khare: Extract_sentiment, Recommend, Chatbot theme, Disambiguate, Extract-titles, find movies by title, Dialogue

########################################################################################
# Ethics Question                                                                      #
########################################################################################

Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, 
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, 
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online 
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced 
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear 
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that 
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

We see that there are plenty of ramifications of anthropomorphizing chatbots. If we take anthropomorphize as attributing
human characteristics to an object (in this scenario, a chatbot), it can lead to the spread of misinformation as well as
the misplacement of trust from users. We see that if users are too trusting of the chatbot's advice and suggestions
(which may not completely be based on fully sound reasoning as they are often the compilation of millions of data points
and datasets). One example, is in the area of diagnosis. If chatbots and neural networks are entrusted by the general
public to give medical diagnosis, without directly backed up human approval, people may get misdiagnosed - which can
either increase worry or do the opposite and cause serious medical issues. This is because it is hard to distinguish the
sources and validity from where the chatbots have ascertained the information. To help this issue, we can ensure that
users can easily distinguish chatbot responses from those of a human, for example including certain cues to show that it
is a bot rather than a real-life human. The overall goal is to ensure that users know that they are interacting with a 
hatbot and not a human, and hence understand the current-day limitations of chatbots knowledges and capabilities. 




#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
We added a Pirate theme for our chatbot to make the bot fun to interact with! In addition,
the pirate speaks somewhat choppily — this is an intentional feature that is part of the
Pirate theme. 
