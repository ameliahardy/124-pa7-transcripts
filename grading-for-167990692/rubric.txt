#########################################################################################
# TODO: Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): YES
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): YES
FEATURE - Alternate/foreign titles: YES
FEATURE - Disambiguation (part 1): YES
FEATURE - Fine-grained sentiment extraction: YES
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: YES
FEATURE - Disambiguation (part 2): YES
FEATURE - Dialogue for spell-checking: YES
FEATURE - Dialogue for disambiguation: NO
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: NO
FEATURE - Responding to arbitrary input: YES
FEATURE - Identifying and responding to emotions: NO
FEATURE - Chatbot theme/persona: YES
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################
Phuc - extract_titles, find_movies_by_title, extract_sentiment, extract_sentiment_for_movies, disambiguate, binarize, similarity, added support for alternate title, greeting, goodbye, process, support for no quotations, find_movies_closest_to_title, recommend, dialogue support for spell-checking
Evan - extract_titles, find_movies_by_title, extract_sentiment, extract_sentiment_for_movies, disambiguate, binarize, similarity, added support for foreign titles
Caroline - extract_sentiment, process, find_movies_by_title, extract_sentiment
Nolawi Ayelework - extract_sentiment, process, find_movies_by_title, extract_sentiment, ethics

#########################################################################################
# Ethics Question                                                                  #
#########################################################################################
Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, 
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, 
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online 
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced 
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear 
that they were written by a human.

One possible ramification of this anthropomorphization is that people will be more willing to ask advice from a chatbot than from a human, especially on topics that could tend to be more embarrassing to talk about with another person. However, some of these topics, like when they relate to therapy or more psychological issues, would better be answered by professionals who can look more holistically at a person, rather than a chatbot that would only consult the knowledge that it knows from websites or other info. Another potential pitfall could be that people who are naturally socially awkward could feel like it is easier to stay secluded rather than try to meet new people, even if they are unhappy with being isolated. 

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that 
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

One possible way that software engineers could help to distinguish the responses is to maybe put a disclaimer at the end of each response the chatbot gives noting that it is a chatbot and not a human. This could be especially significant when it relates to psychological issues, where saying that psychologists should be the first line of support rather than chatbots would be extremely helpful in making it clear that the chatbot shouldn’t replace human intervention.




#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
(optional) If you have anything else you want to add, delete this and type it here!

Caroline had a concussion recently and looking at screens was difficult. Additionally, to support no quotations we fun preprocess_input first to match movies and then add quotations around them. Since it happens outside of extract_title we aren't passing any of the tests. 
