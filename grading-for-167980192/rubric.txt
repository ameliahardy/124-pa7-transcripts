#########################################################################################
# TODO: Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): NO
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): NO
FEATURE - Alternate/foreign titles: YES
FEATURE - Disambiguation (part 1): YES
FEATURE - Fine-grained sentiment extraction: YES
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: YES
FEATURE - Disambiguation (part 2): YES
FEATURE - Dialogue for spell-checking: NO
FEATURE - Dialogue for disambiguation: NO
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: YES
FEATURE - Responding to arbitrary input: YES
FEATURE - Identifying and responding to emotions: NO
FEATURE - Chatbot theme/persona: NO
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################
Caia and Briana worked on recommend. Caia initialized functions like similarity,
distance, binarize, etc. Jacopo and Briana worked on extract_sentiment. Jacopo
worked on disambiguate and it's creatives. Jacopo and Caia worked on movies_closest_to_title.
Briana worked on the ethics question response, fine-grained sentiment extraction, and
alternate/foreign titles. Caia worked on spell-correcting fallback, multiple-movie input, and
attempted to identify movies w/o quotes and correct capitalization.

#########################################################################################
# Ethics Question                                                                  #
#########################################################################################
Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, 
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, 
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online 
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced 
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear 
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that 
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

ANSWER:
Anthropomorphizing chatbot systems can have several potential ramifications. One of the main concerns is that
users may place too much trust in the chatbot's responses and take its advice without question. This could be
especially problematic if the chatbot is providing medical or legal advice, where incorrect information could
have serious consequences. Additionally, if the chatbot is used in a customer service role, users may become 
frustrated or angry if they believe they are interacting with a human representative who is not providing
satisfactory assistance.

To ensure that users can easily distinguish between chatbot responses and those of a human, engineers can
employ a few strategies. One method is to include a disclaimer at the beginning of the interaction,
stating that the user is interacting with a chatbot and not a human.

#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
(optional) If you have anything else you want to add, delete this and type it here!
