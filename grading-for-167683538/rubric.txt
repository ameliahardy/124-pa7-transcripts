#########################################################################################
# TODO: Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): YES
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): YES
FEATURE - Alternate/foreign titles: NO
FEATURE - Disambiguation (part 1): YES
FEATURE - Fine-grained sentiment extraction: YES
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: NO
FEATURE - Disambiguation (part 2): YES
FEATURE - Dialogue for spell-checking: NO
FEATURE - Dialogue for disambiguation: YES
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: NO
FEATURE - Responding to arbitrary input: YES
FEATURE - Identifying and responding to emotions: NO
FEATURE - Chatbot theme/persona: YES
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################
Kaitlin Peng worked on extract_sentiment and fine_grained sentiment extraction.
Lee Rosenthal worked on theme/persona and extract_titles.
Karina Chen worked on find_movies_by_title, find_movies_closest_to_title, and arbitrary output.
Daniel Lee worked on process, disambiguation, extract_titles creative, binarize, find_movies_by_title bad capitalization, and collaborative filtering.

#########################################################################################
# Ethics Question                                                                  #
#########################################################################################

Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, 
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, 
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online 
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced 
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear 
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that 
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

One consequence is if users think that the chatbot is a real person and actually knows what it's talking about, even though in reality, it is a chatbot, it will trust the chatbot as much as it trusts another person, which might be dangerous if the chatbot is trained on harmful and incorrect data. Another consequence is that if users get emotionally attached to the chatbot, they might input sensitive information, which could be bad if the data got leaked. Also, the users might get too attached to the chatbot, which could cause emotional damage when they stop using the chatbot or if it goes out of service.
One way engineers could ensure that users can easily distinguish the chatbot responses from those of a human is to make the chatbot repeat phrases, which will damage the realisticness of the chatbot but will ensure that humans can tell that it is merely a machine, not an actual human, which will make it easy for users to not completely trust the chatbot.

#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
Our persona is a southern-themed chatbot.
