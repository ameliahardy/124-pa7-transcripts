#########################################################################################
# TODO: Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): YES
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): YES
FEATURE - Alternate/foreign titles: NO
FEATURE - Disambiguation (part 1): NO
FEATURE - Fine-grained sentiment extraction: NO
FEATURE - Spell-correcting fallback for find_movies_by_title: NO
FEATURE - Extracting sentiment with multiple-movie input: YES
FEATURE - Disambiguation (part 2): YES
FEATURE - Dialogue for spell-checking: NO
FEATURE - Dialogue for disambiguation: NO
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: NO
FEATURE - Responding to arbitrary input: YES
FEATURE - Identifying and responding to emotions: YES
FEATURE - Chatbot theme/persona: YES
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################

Our project was a full team effort and each person contributed a lot. 
We wrote many of the functions together and really discussed our problem 
solving processes as a team. 

Here are some of the functions that were spearheaded by individuals: 
Larsen: process() (simple)
Peter: binarize() disambiguate()
Riley: find_movies_by_title()
Luke: extract_sentiment()

As a group, we worked on many of the creative functions together, and we were lucky to 
have such a collaborative team. 

#########################################################################################
# Ethics Question                                                                  #
#########################################################################################

Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, 
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, 
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online 
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced 
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear 
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that 
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

Humans have the ability to exercise their better judgement when speaking. Humans can recognize when certain subjects might not be 
appropriate in conversation. Humans also do a better job understanding sarcasm and using other context clues. Many times, chatbot systems 
will not be able to recognize such behaviors. Chatbots will not be able to see any other outside factors besides the text that it is 
provided with, leading it to not have the full context of a scenario. Furthermore, when we anthromoprphize our systems, they will seem more 
trustworthy due to their humanlike nature. However, we users won't account for the potential of chatbots being trained on false data and 
baised information. However, the system would deliver this false information with utmost confidence and certainty, leading to fake news 
and untrue statements being spread. 

If the chatbot had regular reminders to the user that it is a bot and not a human, users would be less inclined to blindly beleive them. 
For instance, if every few lines the bot reminded the user that it is a bot, users would not fall into the anthormorphizing process that we 
tend to see so commonly. While it can still have the human nature and create a real conversation with its users, these reminders would avoid
users getting carried away by the human like nature. 



#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
(optional) If you have anything else you want to add, delete this and type it here!
