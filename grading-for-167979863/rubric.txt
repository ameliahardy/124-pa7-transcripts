#########################################################################################
# DONE: Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): YES
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): YES
FEATURE - Alternate/foreign titles: YES
FEATURE - Disambiguation (part 1): YES
FEATURE - Fine-grained sentiment extraction: YES
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: YES
FEATURE - Disambiguation (part 2): YES
FEATURE - Dialogue for spell-checking: YES
FEATURE - Dialogue for disambiguation: YES
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: YES
FEATURE - Responding to arbitrary input: YES
FEATURE - Identifying and responding to emotions: YES
FEATURE - Chatbot theme/persona: YES
Did not implement any of the above features: YES

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################
DONE: Please write a short description of what each team member contributed!

Jordan, Ari, Brennan, and Mav all worked together to complete the logic behind both starter and creative mode. After planning out our logic,
we tackled each function togther by having one member coding at their computer while we all looked at the same screen and made comments.
When it came to implementing process we followed the same pattern but first worked to create our own state trees and select whomever's
was the most efficient. When testing, we each individually would test out the functions and chat bot and then divide up bugs to individually fix.


#########################################################################################
# Ethics Question                                                                  #
#########################################################################################
DONE: Please answer the following question:

Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, 
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, 
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online 
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced 
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear 
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that 
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?


Answer:

Anthropomorphizing chatbots can lead to users taking advice from it with a similar level of trust and nuance as if a human spoke
it. People may then replace human learning and conversation with chatbot knowledge. This anthropomorphization may also lead to biased
chatbot results from a source that people may use for true answers. They expect the chatbots response to be correct which may perpetuate
these biases.
 
Engineers may be able to distinguish chatbots from human responses through lack of sentiment or not using the common vernacular. If
chatbots spoke with more precise terminology without sentiment, they could deliver responses that are unemotional and unhuman. However,
this may make the chatbot less useful as the output is less understandable to modern humans.


#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
(optional) If you have anything else you want to add, delete this and type it here!
