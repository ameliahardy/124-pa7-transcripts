#########################################################################################
# TODO: Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): YES
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): YES
FEATURE - Alternate/foreign titles: YES
FEATURE - Disambiguation (part 1): YES
FEATURE - Fine-grained sentiment extraction: NO
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: YES
FEATURE - Disambiguation (part 2): YES
FEATURE - Dialogue for spell-checking: YES
FEATURE - Dialogue for disambiguation: YES
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: YES
FEATURE - Responding to arbitrary input: NO
FEATURE - Identifying and responding to emotions: NO
FEATURE - Chatbot theme/persona: YES
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################
Kathryn: process_line() and associated helper functions, extract_titles() standard version, extract_sentiment(), find_movies_closest_to_title() 
Maya: extract_titles() standard and creative versions, extract_sentiment(), extract_sentiment_for_movies(), binarize(), similarity(), recommend()
Za: find_movies_by_title(), disambiguate(), chatbot persona, ethics question 
#########################################################################################
# Ethics Question                                                                  #
#########################################################################################
TODO: Please answer the following question:

Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, 
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, 
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online 
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced 
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear 
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that 
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

Answer:
As people anthropomorphize chatbot systems, it can become increasingly common for users to become vulernable when sharing with a humanlike chatbot.
People may disclose very intimate secrets or histories with the chatbot since they view it as a neutral agent.
This will cause many ethical considerations since people might start to speak with the chatbot in times of disaster or emergency and the chatbot
might not give the correct advice to the person which leads to safety issues. In addition, these extremely personal chatlogs could be stored in the data of the chatbot
but could become leaked out if the data is not secured properly.
In order to ensure that users can distinguish the chatbot from a human, the engineers should implement traits that are the oppositve of anthropomorphization.
For example, instead of giving it realistic emotions, I would advise engineers to make the chatbot have very flat emotions and very little sentiment understanding.
In addition, I would have it give constant reminders that it is just a chatbot inbetween conversation or when the user gets emotional with the chatbot.
Even as people strive to create human-like agents, it is important to create safety stops so people understand the implications for interaction.



#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
(optional) If you have anything else you want to add, delete this and type it here!
