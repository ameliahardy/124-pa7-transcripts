#########################################################################################
#                                                                                       #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): NO
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): NO
FEATURE - Alternate/foreign titles: YES
FEATURE - Disambiguation (part 1): YES 
FEATURE - Fine-grained sentiment extraction: YES 
FEATURE - Spell-correcting fallback for find_movies_by_title: YES 
FEATURE - Extracting sentiment with multiple-movie input: YES 
FEATURE - Disambiguation (part 2): YES 
FEATURE - Dialogue for spell-checking: YES 
FEATURE - Dialogue for disambiguation: YES 
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: YES
FEATURE - Responding to arbitrary input: YES 
FEATURE - Identifying and responding to emotions: NO
FEATURE - Chatbot theme/persona: YES
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################

Yoonjoo: disambiguate,　process, split starter with Vicky, aribitrary
Vicky: foreign/alternate title, split starter with Yoonjoo, spell check and dialogue
Nathan: extract movies sentiment, multiple movie, fine grain, dialogue, debugging

#########################################################################################
# Ethics Question                                                                  #
#########################################################################################

Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, 
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, 
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online 
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced 
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear 
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that 
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

RESPONSE:
"The main issue that arises when it comes to chatbots is the possibility of generating something unwanted.
anthropomorphizing chatbots and giving them more and more human characteristics and abilities would
lead to them to producing more and more biased or opinionated responses. The feeding of biased data and of
and increased access to real language data would lead to realistic responses, but could misguide users
that the chatbot can develop its own thoughts and process things in the same way a human does. This can lead
to catstrophic implications from a societal stnadpoint as the chatbot could produce offensive and 
immoral content, without structured mediation. Additionally, these chatbots could be used by humans to express
opinions and create content, miseleadingly as a human, creating spam and/or fake content.

To ensure that engineers would be able to distingush between chatbot responsess and those of humans, the
engineers should always go through the fed data sets/neural networks and analyze/work to minimize bias. This
will ensure that the respnoses from the chatbot are most desirable and moral. Engineers could also mark each
response from chatbots with a mandatory sign off or intro, so as to disclaim that this was generated by a non-human
program that is trained on human data. They could also distinguish by ensuring that the chatbot keeps
responses to a specific sentnece structure, so as to discern somewhat reliably which sentences would be generated
by their bot, assuming that the chosen sentence structure is abnormal enough (the least sustainable solution). If
the goal from the engineers is for chatbots to simply resemble language and dialogue and not replicate it to a point 
considered natural or human-like, then the best way to keep distinguishable responses is for a (natural) but set
framework of response(s) and limiting the possible responses that could be provided (i.e. irrelevant content).
Keeping with a consistent theme/purpose and even analyzing (bot created) responses for inherent bias or offensive content before output 
would be the best way for engineers to reduce possible negative consequences from improving chatbots and allow for the
easiest discerning between chatbot responses and human responses."

#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
We also implemented the FEATURE - Chatbot theme/persona but gradescope said it shouldn't be 
in the rubric. We just wanted to note it here as well for points sake!
***Also, the creative extract sentiment/fine-grained extract sentiment does not RETURN 2 or -2
when it should. If you print out the return value before it is returned, it is correct, but for 
some reason, the value returned is not the same. We went to office hours for this issue and
Tolu Oleyeni attempted to help us, but ultimately told us to just make a note of what was going on
with our submission. 