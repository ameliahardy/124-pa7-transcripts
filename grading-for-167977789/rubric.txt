#########################################################################################
# TODO: Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): NO
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): YES
FEATURE - Alternate/foreign titles: YES
FEATURE - Disambiguation (part 1): YES
FEATURE - Fine-grained sentiment extraction: YES
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: NO
FEATURE - Disambiguation (part 2): YES
FEATURE - Dialogue for spell-checking: YES
FEATURE - Dialogue for disambiguation: YES
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: NO
FEATURE - Responding to arbitrary input: YES
FEATURE - Identifying and responding to emotions: YES
FEATURE - Chatbot theme/persona: YES
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################
Jenna: Contributed the most to the chatbot persona and fleshing out the process function.
Bryant: Handled the bulk of the complicated coding functions and debugging issues.
Dylan: Added a few of the creative features as well as help with debugging.


#########################################################################################
# Ethics Question                                                                  #
#########################################################################################

Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, 
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, 
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online 
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced 
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear 
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that 
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

Today, newer chatbots employ neural networks which are trained on large datasets from social media platforms like Reddit and Twitter. 
Unfortunately, these datasets often contain offensive text, which can inadvertently be reproduced in chatbot responses. Furthermore, advanced models like GPT-3 have produced responses that closely resemble those written by humans.
The potential ramifications of anthropomorphizing chatbots are significant. If users believe chatbots have human-like qualities, they may trust and rely on their advice despite the chatbot's lack of knowledge or expertise. 
This could lead to users making decisions based on erroneous information, potentially resulting in negative consequences.
To ensure that users can distinguish between chatbot responses and those of a human, engineers could incorporate design features such as clear labeling or visual cues that indicate when the response is generated by a chatbot. 
Additionally, developers could implement strategies to filter out offensive language in the training data to avoid reproducing it in chatbot responses. 
Finally, chatbots could be programmed to provide disclaimers and indicate their limitations when providing information or advice to users.


#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
(optional) If you have anything else you want to add, delete this and type it here!
