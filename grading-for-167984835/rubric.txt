#########################################################################################
# Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): YES
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): YES
FEATURE - Alternate/foreign titles: YES
FEATURE - Disambiguation (part 1): YES
FEATURE - Fine-grained sentiment extraction: YES
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: YES
FEATURE - Disambiguation (part 2): YES
FEATURE - Dialogue for spell-checking: YES
FEATURE - Dialogue for disambiguation: YES
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: YES
FEATURE - Responding to arbitrary input: YES
FEATURE - Identifying and responding to emotions: NO
FEATURE - Chatbot theme/persona: YES
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################
Andrew - Worked on find_movies_by_title, extract_titles, process, and ethics responses
Emma - Worked on extract_titles, extract_sentiment, binarize, and process
Gwen - Worked on extract_titles, extract_sentiment, binarize, and disambiguate
Mahathi - Worked on recommend, find_movies_closest_to_title, extract_titles, and process
#########################################################################################
# Ethics Question                                                                  #
#########################################################################################

Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

One negative ramification of anthropomorphizing chatbot systems is that it could erode the needed healthy amount of skepticism of AI systems like chatbot systems amongst humans using chatbots. AI is not human, but a product of engineers and the training data engineers choose to use to create the chatbot. Engineers are both unrepresentative of the general population and therefore biased, as well as prone to errors (as all humans are, especially in new frontiers like AI). So while AI chatbot systems appear to be perfectly human when anthropomorphized, they are not. That could lead to many things, including overreliance and overconfidence on objective incorrect information generated by chatbots, usage of faulty chatbots (and their inevitable shortcomings)  in education to either replace teachers or student work thereby demeaning education systems, human adoption/exacerbation of racial or social biases that exist in chatbots who train on data that contains such biases. AI chatbots should be treated as AI chatbots and all of the benefits and shortcomings of chatbots so they can be optimally and ethically used for human society; AI chatbots should NOT be treated as humans because they are prone to unique, and potentially catastrophic, errors that when gone unchecked by adequate skepticism could cause detrimental consequences in human society.

To ensure users can easily distinguish between chatbot and human responses, engineers should start sentences or responses from chatbots with a clause that transparently signifies that the response is coming from an algorithm that has both potential errors and was generated from data (it would be good to describe the training data used in this response) instead of a human brain. For example, they could start a response about movie recommendations with “Based on an algorithmic review of 10,000 movies on XYZ website in the United States and Europe from YEAR-YEAR, …”. This way, the chatbot signifies that it is generating its response (recommendations) from an algorithm instead of human cognition by using “Based on an algorithm review…” and it states where it’s getting its data from by saying “XYZ website in the United States and Europe from YEAR-YEAR, …”. This allows the users to distinguish that this chatbot response is not human-generated, but AI-generated.




#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
We have designed the system under the assumption that each component of the rubric will be graded independently—We asked on Ed, and this is what the TA told us! For instance, our extract_sentiment_for_movies might not be able to handle spellcheck or disambiguate, although it certainly extracts sentiment for multiple movies!  

For find_movies_by_title(), the creative feature disambiguate part 1 (test 2d) is the only creative feature that needed the if self.creative: if expression. The other find_movie_by_title() creative features work integrated in starter mode as well. We coded it this way from initial confusion on how and where to put code for creative features within starter more function. But the 2a, 2b, 2c starter/creative function tests all need to have the same logic to work and work harmoniously when both self.creative==True and self.creative==False.