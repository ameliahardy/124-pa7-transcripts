#########################################################################################
# TODO: Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): NO
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): NO
FEATURE - Alternate/foreign titles: NO
FEATURE - Disambiguation (part 1): YES
FEATURE - Fine-grained sentiment extraction: YES
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: YES
FEATURE - Disambiguation (part 2): YES
FEATURE - Dialogue for spell-checking: NO
FEATURE - Dialogue for disambiguation: YES
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: NO
FEATURE - Responding to arbitrary input: YES
FEATURE - Identifying and responding to emotions: YES
FEATURE - Chatbot theme/persona: YES
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################

Marielle: Wrote Process, also wrote initial drafts of the starter code functions except the recommend/similarity/binarize functions. Contributed a paragraph to ethics. 
Ahmad: Write Exact Sentiment with Multiple Movie Input. Also wrote initial drafts of the recommend/similarity/binarize starter code functions. Contributed a paragraph to ethics. 
Rupert: Wrote binaries, extract sentiment, find movies, find closest movies (edit distance), recommend
Saahil: Wrote binaries, extract sentiment, find movies, find closest movies (edit distance), recommend (Rupert and Saahil collaborated together on these function)


#########################################################################################
# Ethics Question                                                                  #
#########################################################################################

Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, 
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, 
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online 
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced 
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear 
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that 
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

-----

I am a movie chatbot. I gather top intel on the movies and tell you all about it. You can chat with me, and based on your previous tastes, I'll recommend new movies for you to watch. Tell me about your tastes, and I'll listen. Based on our chat, I'll generate some recommendations. I'll try to be friendly.

Possible ramifications of anthropomorphizing chatbot systems may lead people to trust the systems more than they should. Then people may give out personal information that the chatbot would be storing, or share deeply personal details with the chatbot, which it may not be equipped to properly handle. While any normal human may also not be equipped to handle this issue, because the chatbot is programmed and can be made to largely guarantee a certain frame of response, chatbot builders have the responsibility to make sure they don't build chatbots that would algorithmically handle people incorrectly - e.g. give an unsympathetic response to a person contemplating suicide. Other ramifications can be that people have been shown to get PTSD more commonly from horrors inflicted purposefully on them by another person than by natural processes (e.g. war vs. hurricane). Should the chatbot parrot triggering or offensive language, and the user believe it human, this would contribute to the same harm as if another person said it, whereas if the user simply believes the truth, that the chatbot was unfortunately trained on harmful content but that it is simply statistically parroting some information back to the user, they will likely be less harmed. Some ways engineers could ensure users can easily distinguish the chatbot responses from those of a human could be to put some sort of marker at the end of chatbot sentences. Unfortunately, I don't think this would convince people this is machinery not human. Likely the only way to do that is to reduce the user experience quality of the chatbot, and to have it return such responses as it used to give - robotic and strange - rather than natural and humanlike. 


#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
(optional) If you have anything else you want to add, delete this and type it here!
Our Chatbot Character is a cat!
