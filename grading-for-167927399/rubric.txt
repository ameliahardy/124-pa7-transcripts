#########################################################################################
# TODO: Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): YES
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): YES
FEATURE - Alternate/foreign titles: YES
FEATURE - Disambiguation (part 1): YES
FEATURE - Fine-grained sentiment extraction: NO
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: YES
FEATURE - Disambiguation (part 2): YES
FEATURE - Dialogue for spell-checking: YES
FEATURE - Dialogue for disambiguation: NO
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: YES
FEATURE - Responding to arbitrary input: YES
FEATURE - Identifying and responding to emotions: YES
FEATURE - Chatbot theme/persona: YES
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################
TODO: When tackling this assignment, we began by splitting up the starter functions such that
each person was in charge of writing the code for at least one function. If we faced issues, 
we assisted one another and collaborated using git. Once our starter code was finished, 
we then each chose to take on different creative functions and marked which ones we completed
using a copy of the rubric spreadsheet. 




#########################################################################################
# Ethics Question                                                                  #
#########################################################################################
TODO: Anthromorphizing chatbot systems may lead to negative consequences concerning privacy, safety, over-reliance,
representational harm, and privacy. To begin, privacy is a major point of contention as any dialogue system
can have potential leakage of sensitive information like passwords. Another issue is that users may trust chatbots too much and rely too
heavily on their advice that may be false or dangerous. Furthermore, users may develop emotional attachments to chatbots,
leading to distress if the chatbot is discontinued or behaves inappropriately. Moreover, chatbots trained on data from online sources, like Reddit and Twitter,
may reproduce offensive or harmful language, which can result in abuse and representational harm to individuals or groups. For instance,
Microsoft's chatbot Tay, which was designed to mimic the language of a teenage girl, began posting messages with racial slurs,
conspiracy theories, and personal attacks on its users after just a few hours of interacting with online users.

To mitigate these concerns, engineers can take several steps to facilitate users in differentiating between chatbot and human responses.
Providing educational resources to users about the capabilities and limitations of chatbots can help them analyze responses more critically.
Embedding distinct visual cues, such as text formatting or icons, to clearly mark chatbot responses can help avoid any confusion with human responses.
Chatbot systems could also incorporate a disclaimer at the beginning of the conversation, explicitly stating that the user is interacting with a chatbot.

Additionally, engineers can restrict the range of responses that chatbots are programmed to give, to ensure that they do not generate
any offensive or unsuitable content. They can also utilize methods such as sentiment analysis or content filtering to detect and remove harmful language.
By adopting such techniques, engineers can reduce the negative effects of anthromorphizin chatbots and promote user security and confidentiality.

––––


Humans are quick to anthropomorphize chatbots, like ELIZA.
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice,
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks,
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?



#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
(optional) If you have anything else you want to add, delete this and type it here!
