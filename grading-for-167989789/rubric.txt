#########################################################################################
# TODO: Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): YES
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): YES
FEATURE - Alternate/foreign titles: YES
FEATURE - Disambiguation (part 1): YES
FEATURE - Fine-grained sentiment extraction: YES
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: YES
FEATURE - Disambiguation (part 2): YES
FEATURE - Dialogue for spell-checking: YES
FEATURE - Dialogue for disambiguation: YES
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: YES
FEATURE - Responding to arbitrary input: YES
FEATURE - Identifying and responding to emotions: YES
FEATURE - Chatbot theme/persona: YES
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################
Please write a short description of what each team member contributed!

Tiantian: Implemented extract_sentiment (starter and creative), process (starter and creative),
extract_sentiment (starter and creative), extract_titles (creative), find_movies_by_title (creative),
extract_sentiment_for_movies, and disambiguate.
Si Yi: Implemented extract_titles, binarize, and added persona to the chatbot.
Michelle:  Focused on find_movies_by_title (starter and creative).
Clara: Implemented recommend, find_movies_by_title (creative), process, and disambiguate.
As a team, we were effective at communication, delegation, and planning.

#########################################################################################
# Ethics Question                                                                  #
#########################################################################################
Please answer the following question:

Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, 
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, 
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online 
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced 
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear 
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that 
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

Chatbot is an AI tool that can understand and answer questions. Anthropomorphizing chatbot systems may lead to unnecessary complex systems. Sometimes, people would prefer a simple and efficient interface without the hassle of a conversation over a "fake" human being. Studies have found that people will react to computers in the same manner as to other people, meaning that people interact with computers just like interactions in everyday life. This could be an issue when people start to rely on and trust the chatbot, especially when the chatbot is not programmed to provide reliable, unbiased, or accurate information. Furthermore, people may also become emotionally attached to chatbots because they are designed to make people think that they can understand complex emotions and behave in similar ways.

To ensure that users can easily distinguish the chatbot responses from those of a human, engineers could include disclaimers in the chatbot's responses, making it clear to users that they are interacting with a machine and not a human. Additionally, the engineer could also add a distinct persona for the chatbot that is not human-like. For example, the chatbot could have a robotic voice or use unusual phrasings that are clearly not human-like.

#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
(optional) If you have anything else you want to add, delete this and type it here!
